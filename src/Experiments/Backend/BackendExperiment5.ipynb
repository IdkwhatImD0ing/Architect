{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Backend Experiment Number 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this experiment is to see if we can combine the chains in experiments one and two into one chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import openai\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import asyncio\n",
    "\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from pydantic import Extra\n",
    "\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.schema import BasePromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_details=\"\"\"\n",
    "We're building a comprehensive smart city solution, aiming to enhance the quality of urban life by using digital technology. This solution will have numerous interconnected components and features:\n",
    "\n",
    "Smart Traffic Management System: Uses AI to analyze real-time traffic data, predict congestion, and control traffic lights to optimize traffic flow. It will also include a predictive maintenance system for traffic infrastructure.\n",
    "\n",
    "Public Safety System: Incorporates facial recognition technology and predictive policing algorithms to ensure safety. This system will integrate with city surveillance cameras and police databases.\n",
    "\n",
    "Waste Management System: Implements smart bins equipped with sensors to monitor waste levels and schedule optimal pick-up times.\n",
    "\n",
    "Smart Energy Grid: Enables real-time monitoring of energy consumption and supply at an individual household level, while also integrating renewable energy sources.\n",
    "\n",
    "Urban Farming: Incorporates vertical farming technologies, automated irrigation systems, and AI-powered pest prediction and prevention.\n",
    "\n",
    "E-Government Portal: A central web portal for all government services, integrating multiple departmental systems and databases, complete with secure identity verification and multi-language support.\n",
    "\n",
    "Public Transportation System: A fully automated scheduling and ticketing system for all city public transportation, including buses, subways, and bike rentals. It will use AI to optimize routes and schedules based on real-time data.\n",
    "\n",
    "Environment Monitoring: Implementing IoT sensors across the city to monitor air and water quality in real time.\n",
    "\"\"\"\n",
    "project_technologies=\"\"\"\n",
    "The project will be developed using a range of technologies including, but not limited to, Python, TensorFlow, React.js, Node.js, PostgreSQL, Docker, Kubernetes, AWS, IoT protocols, and various data science and AI/ML libraries.\n",
    "\n",
    "This system will have to comply with stringent regulations and standards for data security and privacy, including GDPR and ISO 27001. It will also require robust scalability, fault tolerance, and multi-region availability to cater to the entire city's population.\n",
    "\n",
    "Additionally, the system will need to be user-friendly, accessible, and offer multi-language support to cater to the diverse user base in the city.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Backend Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def backend_func(\n",
    "        inputs: Dict[str, Any],\n",
    "        llm: BaseLanguageModel,\n",
    "        advanced_llm: BaseLanguageModel,\n",
    "    ) -> str:\n",
    "        # Feature Extraction\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"project_details\", \"project_technologies\"],\n",
    "            template=\"\"\"\n",
    "            Given the following project description and tech stack, identify and elaborate on the key backend features that would be necessary for development. The backend features should not involve any frontend components or styling. The backend features should be described in terms of capabilities.\n",
    "            This project is a hackathon project. Break apart the features into MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "            Project description: {project_details}\n",
    "            Technologies: {project_technologies}\n",
    "            \"\"\"\n",
    "        )\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        backend_features = await chain.arun(inputs)\n",
    "        \n",
    "        # Specification Creation\n",
    "        specification_prompt = PromptTemplate(\n",
    "            input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "            template=\"\"\"\n",
    "            Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "            This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "            However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "            You should ignore the technologies for the frontend and focus on the backend.\n",
    "            Please also mention any other technical considerations.\n",
    "            \n",
    "            Backend Features: {backend_features}\n",
    "            \n",
    "            Project Technologies: {project_technologies}\n",
    "            \"\"\"\n",
    "        )\n",
    "        specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "        specification = await specification_chain.arun({\n",
    "            'backend_features': backend_features,\n",
    "            'project_technologies': inputs['project_technologies']\n",
    "        })\n",
    "        \n",
    "        approval_prompt = PromptTemplate(\n",
    "            input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "            template=\"\"\"\n",
    "            Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "            Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people, considering the complexity and the technology stack required.\n",
    "            \n",
    "            The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "            Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "            This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "            Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level: {group_experience}?\n",
    "            Output only a json with keys 'approval' and 'comments'. \n",
    "            If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "            If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "            Technical Specification: {technical_specification}\n",
    "            \n",
    "            Output only a json with keys 'approval' and 'comments'. \n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "        approval = await approval_chain.arun({\n",
    "            'technical_specification': specification,\n",
    "            'aspect': 'backend',\n",
    "            'group_size': inputs['group_size'],\n",
    "            'group_experience': inputs['group_experience']\n",
    "        })\n",
    "        \n",
    "        if '```json' in approval:\n",
    "            approval = approval.split('```json')[1]\n",
    "            approval = approval.split('```')[0]\n",
    "        \n",
    "        approvals_object = json.loads(approval)\n",
    "        \n",
    "        return_obj = {\n",
    "            'approval': approvals_object['approval'],\n",
    "            'comments': approvals_object['comments'],\n",
    "            'features': backend_features,\n",
    "            'specifications': specification\n",
    "        }\n",
    "        \n",
    "        return json.dumps(return_obj)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing this custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4\")\n",
    "advanced_llm = ChatOpenAI(temperature=0, max_tokens=1000, model=\"gpt-4-1106-preview\")\n",
    "\n",
    "output = await backend_func(\n",
    "    inputs = {\n",
    "        'project_details': project_details,\n",
    "        \"project_technologies\": project_technologies,\n",
    "        \"group_size\": 4,\n",
    "        \"group_experience\": \"experienced\"\n",
    "    },\n",
    "    llm=llm,\n",
    "    advanced_llm=advanced_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approval': 0,\n",
       " 'comments': 'The MVP features include complex tasks such as developing AI/ML models with TensorFlow, which alone could take more than two days to properly implement, train, and test. Additionally, setting up a secure and scalable infrastructure with Docker and Kubernetes within the same timeframe is highly ambitious. While experienced developers might be able to set up basic APIs and database schemas, ensuring GDPR and ISO 27001 compliance for security in a two-day hackathon is unrealistic. The combination of these tasks is too complex to be completed to a satisfactory standard within the given time frame for an MVP.',\n",
       " 'features': \"MVP Backend Features:\\n\\n1. Data Management: A robust database system to store and manage data from various sources like traffic, waste management, energy consumption, etc. PostgreSQL can be used for this purpose.\\n\\n2. API Development: APIs to interact with various components of the system like traffic lights, smart bins, energy grid, etc. These APIs will facilitate data exchange between different components and the central system.\\n\\n3. AI/ML Models: Development of AI/ML models using TensorFlow to analyze data and make predictions. For example, predicting traffic congestion, optimal waste pick-up times, energy consumption patterns, etc.\\n\\n4. Security: Implementation of stringent security measures to protect data and comply with regulations like GDPR and ISO 27001. This includes secure identity verification for the e-government portal.\\n\\n5. Scalability: The system should be designed to handle large amounts of data and users. This can be achieved using technologies like Docker and Kubernetes.\\n\\nAdditional Backend Features:\\n\\n1. Integration with External Systems: The system should be able to integrate with external systems like city surveillance cameras, police databases, public transportation systems, etc.\\n\\n2. Real-time Monitoring: Implement real-time monitoring of various parameters like traffic, waste levels, energy consumption, air and water quality, etc.\\n\\n3. Predictive Maintenance: Implement predictive maintenance algorithms for traffic infrastructure and other city assets.\\n\\n4. Automated Scheduling: Develop algorithms for automated scheduling of tasks like waste pick-up, public transportation, irrigation in urban farms, etc.\\n\\n5. Multi-region Availability: The system should be available in multiple regions to cater to the entire city's population. This can be achieved using AWS.\\n\\n6. Multi-language Support: The system should support multiple languages to cater to the diverse user base in the city.\\n\\n7. IoT Integration: Implement IoT protocols to interact with various IoT devices like traffic lights, smart bins, energy meters, environmental sensors, etc.\",\n",
       " 'specifications': \"Technical Specification:\\n\\nMVP Backend Features:\\n\\n1. Data Management: PostgreSQL will be used as the primary database system. It will store and manage data from various sources like traffic, waste management, energy consumption, etc. \\n\\n2. API Development: APIs will be developed using Node.js. These APIs will interact with various components of the system like traffic lights, smart bins, energy grid, etc. \\n\\n3. AI/ML Models: TensorFlow will be used to develop AI/ML models. These models will analyze data and make predictions like traffic congestion, optimal waste pick-up times, energy consumption patterns, etc.\\n\\n4. Security: Security measures will be implemented to protect data and comply with regulations like GDPR and ISO 27001. This includes secure identity verification for the e-government portal.\\n\\n5. Scalability: Docker and Kubernetes will be used to ensure the system can handle large amounts of data and users.\\n\\nAdditional Backend Features:\\n\\n1. Integration with External Systems: The system will integrate with external systems like city surveillance cameras, police databases, public transportation systems, etc.\\n\\n2. Real-time Monitoring: Real-time monitoring of various parameters like traffic, waste levels, energy consumption, air and water quality, etc. will be implemented.\\n\\n3. Predictive Maintenance: Predictive maintenance algorithms will be developed for traffic infrastructure and other city assets.\\n\\n4. Automated Scheduling: Algorithms for automated scheduling of tasks like waste pick-up, public transportation, irrigation in urban farms, etc. will be developed.\\n\\n5. Multi-region Availability: AWS will be used to ensure the system is available in multiple regions.\\n\\n6. Multi-language Support: The system will support multiple languages.\\n\\n7. IoT Integration: IoT protocols will be implemented to interact with various IoT devices like traffic lights, smart bins, energy meters, environmental sensors, etc.\\n\\nHardware and Startup Costs:\\n\\nThe hardware costs will include servers for hosting the application, storage devices for storing data, and networking equipment for connecting the various components. The startup costs will include the cost of developing the application, purchasing the necessary hardware, and setting up the infrastructure.\\n\\nOther Technical Considerations:\\n\\nThe system will need to comply with stringent regulations and standards for data security and privacy, including GDPR and ISO 27001. It will also require robust scalability, fault tolerance, and multi-region availability to cater to the entire city's population. Additionally, the system will need to be user-friendly, accessible, and offer multi-language support to cater to the diverse user base in the city.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def backend_revision(\n",
    "        inputs: Dict[str, Any],\n",
    "        llm: BaseLanguageModel,\n",
    "        advanced_llm: BaseLanguageModel,\n",
    "    ) -> str:\n",
    "        # Revision Prompt\n",
    "        revision_prompt = PromptTemplate(\n",
    "            input_variables=[\"original_features\", \"comments\"],\n",
    "            template=\"\"\"\n",
    "            Given the original features and the comments provided after the feasibility evaluation, modify the original features to make them simpler and more feasible for a two-day hackathon.\n",
    "            The aim is to reduce the complexity and scope of the original features while preserving the core functionality of the system. \n",
    "            The comments provide specific areas of concern that should be addressed in the modified features.\n",
    "\n",
    "            Original Features: {original_features}\n",
    "            Comments: {comments}\n",
    "\n",
    "            Based on this, please provide a simplified version of the original features that addresses the concerns mentioned in the comments.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        revision_chain = LLMChain(llm=llm, prompt=revision_prompt)\n",
    "        backend_features = await revision_chain.arun({\n",
    "            'original_features': inputs['features'],\n",
    "            'comments': inputs['comments']\n",
    "        })\n",
    "\n",
    "        \n",
    "        # Specification Creation\n",
    "        specification_prompt = PromptTemplate(\n",
    "            input_variables=[\"backend_features\", \"project_technologies\"],\n",
    "            template=\"\"\"\n",
    "            Given the extracted backend features and the specified skills/technologies, create a detailed technical specification. \n",
    "            This specification should include the technologies to be used, the architecture, the different routes/endpoints, their inputs and outputs, and any potential hardware and startup costs.\n",
    "            However, they should be split into two categories: MVP and additional features. The MVP should be the minimum features necessary to have a working prototype.\n",
    "            You should ignore the technologies for the frontend and focus on the backend.\n",
    "            Please also mention any other technical considerations.\n",
    "            \n",
    "            Backend Features: {backend_features}\n",
    "            \n",
    "            Project Technologies: {project_technologies}\n",
    "            \"\"\"\n",
    "        )\n",
    "        specification_chain = LLMChain(llm=llm, prompt=specification_prompt)\n",
    "        specification = await specification_chain.arun({\n",
    "            'backend_features': backend_features,\n",
    "            'project_technologies': inputs['project_technologies']\n",
    "        })\n",
    "        \n",
    "        approval_prompt = PromptTemplate(\n",
    "            input_variables=[\"technical_specification\", \"aspect\", \"group_size\", \"group_experience\"],\n",
    "            template=\"\"\"\n",
    "            Given the developed technical specification, conduct a thorough review of the MVP Features only for any inconsistencies or issues. \n",
    "            Also, evaluate whether the MVP Features, can be realistically completed within the two day hackathon for {group_size} people, considering the complexity and the technology stack required.\n",
    "            \n",
    "            The MVP Features are specifically listed under the heading 'MVP Features'. \n",
    "            Please completely disregard any features or sections listed under 'Additional Features' or any similar headers.\n",
    "            This specification is only for the {aspect} aspect of the project, and should not be evaluated for other aspects.\n",
    "\n",
    "            Answer this question: Can the MVP Features be realistically completed within the two day hackathon for {group_size} people with this skill level: {group_experience}?\n",
    "            Output only a json with keys 'approval' and 'comments'. \n",
    "            If yes, the value of 'approval' should be '1' and the value of 'comments' should be an empty string\n",
    "            If not, the value of 'approval' should be '0' and the value of 'comments' should be a string with the issues and inconsistencies listed.\n",
    "\n",
    "            Technical Specification: {technical_specification}\n",
    "            \n",
    "            Output only a parsable one line json with keys 'approval' and 'comments'. \n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        approval_chain = LLMChain(llm=advanced_llm, prompt=approval_prompt)\n",
    "        approval = await approval_chain.arun({\n",
    "            'technical_specification': specification,\n",
    "            'aspect': 'backend',\n",
    "            'group_size': inputs['group_size'],\n",
    "            'group_experience': inputs['group_experience']\n",
    "        })\n",
    "        \n",
    "        approvals_object = json.loads(approval)\n",
    "        \n",
    "        if '```json' in approval:\n",
    "            approval = approval.split('```json')[1]\n",
    "            approval = approval.split('```')[0]\n",
    "        \n",
    "        return_obj = {\n",
    "            'approval': approvals_object['approval'],\n",
    "            'comments': approvals_object['comments'],\n",
    "            'features': backend_features,\n",
    "            'specifications': specification\n",
    "        }\n",
    "        \n",
    "        return json.dumps(return_obj)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mi:\\Github\\Architect\\src\\Experiments\\Backend\\BackendExperiment5.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m inputs[\u001b[39m'\u001b[39m\u001b[39mgroup_size\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m inputs[\u001b[39m'\u001b[39m\u001b[39mgroup_experience\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexperienced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m backend_revision(\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     llm\u001b[39m=\u001b[39mllm,\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     advanced_llm\u001b[39m=\u001b[39madvanced_llm\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m obj \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(obj[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mi:\\Github\\Architect\\src\\Experiments\\Backend\\BackendExperiment5.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m approval_chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39madvanced_llm, prompt\u001b[39m=\u001b[39mapproval_prompt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m approval \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m approval_chain\u001b[39m.\u001b[39marun({\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtechnical_specification\u001b[39m\u001b[39m'\u001b[39m: specification,\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbackend\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgroup_size\u001b[39m\u001b[39m'\u001b[39m: inputs[\u001b[39m'\u001b[39m\u001b[39mgroup_size\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgroup_experience\u001b[39m\u001b[39m'\u001b[39m: inputs[\u001b[39m'\u001b[39m\u001b[39mgroup_experience\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m })\n\u001b[1;32m---> <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m approvals_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(approval)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m return_obj \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mapproval\u001b[39m\u001b[39m'\u001b[39m: approvals_object[\u001b[39m'\u001b[39m\u001b[39mapproval\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m: approvals_object[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m: backend_features,\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mspecifications\u001b[39m\u001b[39m'\u001b[39m: specification\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/Github/Architect/src/Experiments/Backend/BackendExperiment5.ipynb#X14sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mdumps(return_obj)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    inputs = json.loads(output)\n",
    "    inputs['project_technologies'] = project_technologies\n",
    "    inputs['group_size'] = 4\n",
    "    inputs['group_experience'] = 'experienced'\n",
    "    output = await backend_revision(\n",
    "        inputs = inputs,\n",
    "        llm=llm,\n",
    "        advanced_llm=advanced_llm\n",
    "    )\n",
    "    obj = json.loads(output)\n",
    "    print(obj['features'])\n",
    "    print(obj['approval'])\n",
    "    print(\"=====================================\")\n",
    "    if(obj['approval'] == 1):\n",
    "        break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Architect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
